// Automatically generated code.  Edit at your own risk!
// Generated by bali2javacc v2002.09.04.

//-----------------------------------//
// Options block:
//-----------------------------------//

// No options blocks defined in Bali grammar.

//-----------------------------------//
// Parser code block:
//-----------------------------------//

PARSER_BEGIN(BaliParser)

package guidsl ;

public class BaliParser {

    private static Model parseRoot = null ;

    public static Model getStartRoot () {
        return parseRoot ;
    }

    public static Model getStartRoot (BaliParser parser)
    throws ParseException {
        try {
            parseRoot = parser.Model () ;
            parser.requireEOF () ;
            return parseRoot ;
        } catch (TokenMgrError error) {
            ParseException e = new ParseException 
            ("token error occurred") ;
            e.initCause (error) ;
            throw e ;
        }
    }

    // Wraps an optional node around an AstNode:
    //
    static AstOptNode opt (AstNode node) {
        return new AstOptNode () . setParms (node) ;
    }
    
    // Wraps an optional node around an AstToken:
    //
    static AstOptToken opt (AstToken token) {
        return new AstOptToken () . setParms (token) ;
    }
    
    // Forces an end-of-file check in the tokenStream:
    //
    public void requireEOF () throws ParseException {
        try {
            jj_consume_token (BaliParserConstants.EOF) ;
        } catch (TokenMgrError error) {
            ParseException e = new ParseException ("EOF error") ;
            e.initCause (error) ;
            throw e ;
        }
    }
    
    // Converts a JavaCC Token to a Bali AstToken:
    //
    static AstToken t2at (Token tok) {
    
        // Special case -- if token is optional:
        //
        if (tok == null)
            return (null) ;
    
        StringBuffer buffer = new StringBuffer () ;
        Token special = tok.specialToken;
        while (special != null) {
            buffer.insert (0, special.toString()) ;
            special = special.specialToken ;
        }
        String white = buffer.toString () ;
    
        return new AstToken().setParms (white, tok.image, tok.endLine) ;
    }

}

PARSER_END(BaliParser)

//-----------------------------------//
// Token manager declarations:
//-----------------------------------//

// No TOKEN_MGR_DECLS defined in Bali grammar.

//-----------------------------------//
// Standard token definitions:
//-----------------------------------//

SPECIAL_TOKEN : {" "|"\f"|"\n"|"\r"|"\t"}

// COMMENTS:

MORE : {
    "//" : IN_SINGLE_LINE_COMMENT
    | <"/**" ~["/"]> { input_stream.backup(1); } : IN_FORMAL_COMMENT
    | "/*" : IN_MULTI_LINE_COMMENT
}

<IN_SINGLE_LINE_COMMENT>
SPECIAL_TOKEN : {
    <SINGLE_LINE_COMMENT: "\n" | "\n\r" | "\r" | "\r\n"> : DEFAULT
}

<IN_FORMAL_COMMENT>
SPECIAL_TOKEN : {
    <FORMAL_COMMENT: "*/" > : DEFAULT
}

<IN_MULTI_LINE_COMMENT>
SPECIAL_TOKEN : {
    <MULTI_LINE_COMMENT: "*/" > : DEFAULT
}

<IN_SINGLE_LINE_COMMENT,IN_FORMAL_COMMENT,IN_MULTI_LINE_COMMENT>
MORE : { < ~[] > }

TOKEN : {
    <#LETTER:
       [
           "\u0024",
           "\u0041"-"\u005a",
           "\u005f",
           "\u0061"-"\u007a",
           "\u00c0"-"\u00d6",
           "\u00d8"-"\u00f6",
           "\u00f8"-"\u00ff",
           "\u0100"-"\u1fff",
           "\u3040"-"\u318f",
           "\u3300"-"\u337f",
           "\u3400"-"\u3d2d",
           "\u4e00"-"\u9fff",
           "\uf900"-"\ufaff"
       ]
    >
|
    < #DIGIT:
       [
            "\u0030"-"\u0039",
            "\u0660"-"\u0669",
            "\u06f0"-"\u06f9",
            "\u0966"-"\u096f",
            "\u09e6"-"\u09ef",
            "\u0a66"-"\u0a6f",
            "\u0ae6"-"\u0aef",
            "\u0b66"-"\u0b6f",
            "\u0be7"-"\u0bef",
            "\u0c66"-"\u0c6f",
            "\u0ce6"-"\u0cef",
            "\u0d66"-"\u0d6f",
            "\u0e50"-"\u0e59",
            "\u0ed0"-"\u0ed9",
            "\u1040"-"\u1049"
       ]
    >
}

//-----------------------------------//
// Bali tokens from grammar:
//-----------------------------------//

// No Bali tokens defined in Bali grammar.

//-----------------------------------//
// Regular-expression tokens from grammar:
//-----------------------------------//

TOKEN: { 
   < STRING_LITERAL:
      "\""
      (   (~["\"","\\","\n","\r"])
        | ("\\"
            ( ["n","t","b","r","f","\\","'","\""]
            | ["0"-"7"] ( ["0"-"7"] )?
            | ["0"-"3"] ["0"-"7"] ["0"-"7"]
            )
          )
      )*
      "\""
  >
}

//-----------------------------------//
// JAVACODE blocks from grammar:
//-----------------------------------//

// No JAVACODE blocks in Bali grammar.

//-----------------------------------//
// Productions from Bali grammar:
//-----------------------------------//

Model Model () : {
    Cons co0=null ;
    Prods pr0=null ;
    Vars va0=null ;
} {
    pr0=Prods()
    [ co0=Cons() ]
    [ va0=Vars() ]
    {return new MainModel().setParms (pr0, opt(co0), opt(va0)) ;}
}

AExpr AExpr () : {
    AExpr ae0=null ;
    NExpr ne0=null ;
    Token to0=null ;
} {
    // Merged productions from rule AExpr
    // (*) NExpr
    // (*) NExpr "and" AExpr :: BAnd
    // 
    ne0=NExpr()
    [
        LOOKAHEAD(2)
        to0="and"
        ae0=AExpr()
        {return new BAnd().setParms (ne0, t2at(to0), ae0) ;}
    ]
    {return (AExpr) ne0 ;}
}

Avar Avar () : {
    Opts op0=null ;
    Token to2=null, to1=null, to0=null ;
} {
    to0=<IDENTIFIER>
    to1="{"
    [ op0=Opts() ]
    to2="}"
    {return new Var().setParms (t2at(to0), t2at(to1), opt(op0), t2at(to2)) ;}
}

AvarList AvarList () : {
    AvarList list = new AvarList () ;
    Avar av0=null ;
} {
    (
        av0=Avar()
        {list.add (new AvarListElem().setParms (av0)) ;}
    )+
    {return list ;}
}

BExpr BExpr () : {
    Expr ex0=null ;
    Token to1=null, to0=null ;
} {
    to0=<IDENTIFIER>
    {return new Bvar().setParms (t2at(to0)) ;}
    |
    to0="("
    ex0=Expr()
    to1=")"
    {return new Paren().setParms (t2at(to0), ex0, t2at(to1)) ;}
}

Cons Cons () : {
    ESList es0=null ;
    Token to0=null ;
} {
    to0="%%"
    es0=ESList()
    {return new ConsStmt().setParms (t2at(to0), es0) ;}
}

EExpr EExpr () : {
    EExpr ee0=null ;
    IExpr ie0=null ;
    Token to0=null ;
} {
    // Merged productions from rule EExpr
    // (*) IExpr
    // (*) IExpr "iff" EExpr :: BIff
    // 
    ie0=IExpr()
    [
        LOOKAHEAD(2)
        to0="iff"
        ee0=EExpr()
        {return new BIff().setParms (ie0, t2at(to0), ee0) ;}
    ]
    {return (EExpr) ie0 ;}
}

ESList ESList () : {
    ESList list = new ESList () ;
    ExprStmt ex0=null ;
} {
    (
        ex0=ExprStmt()
        {list.add (new ESListElem().setParms (ex0)) ;}
    )+
    {return list ;}
}

Expr Expr () : {
    EExpr ee0=null ;
    ExprList ex0=null ;
    Token to2=null, to1=null, to0=null ;
} {
    to0="choose1"
    to1="("
    ex0=ExprList()
    to2=")"
    {return new BChoose1().setParms (t2at(to0), t2at(to1), ex0, t2at(to2)) ;}
    |
    ee0=EExpr()
    {return (Expr) ee0 ;}
}

ExprList ExprList () : {
    ExprList list = new ExprList () ;
    EExpr ee0=null ;
    Token to0=null ;
} {
    ee0=EExpr()
    {list.add (new ExprListElem().setParms (ee0)) ;}
    (
        to0=","
        ee0=EExpr()
        {list.add (new ExprListElem().setParms (t2at(to0), ee0)) ;}
    )*
    {return list ;}
}

ExprStmt ExprStmt () : {
    Expr ex0=null ;
    Token to3=null, to2=null, to1=null, to0=null ;
} {
    ex0=Expr()
    to0=";"
    {return new EStmt().setParms (ex0, t2at(to0)) ;}
    |
    to0="let"
    to1=<IDENTIFIER>
    to2="iff"
    ex0=Expr()
    to3=";"
    {return new VarDef().setParms
    (t2at(to0), t2at(to1), t2at(to2), ex0, t2at(to3)) ;}
}

GProd GProd () : {
    Pats pa0=null ;
    Token to2=null, to1=null, to0=null ;
} {
    to0=<IDENTIFIER>
    to1=":"
    pa0=Pats()
    to2=";"
    {return new GProduction().setParms
    (t2at(to0), t2at(to1), pa0, t2at(to2)) ;}
}

GTerm GTerm () : {
    Token to2=null, to1=null, to0=null ;
} {
    LOOKAHEAD(2) 
    to0=<IDENTIFIER>
    to1="+"
    {return new PlusTerm().setParms (t2at(to0), t2at(to1)) ;}
    |
    LOOKAHEAD(2) 
    to0=<IDENTIFIER>
    to1="*"
    {return new StarTerm().setParms (t2at(to0), t2at(to1)) ;}
    |
    to0=<IDENTIFIER>
    {return new TermName().setParms (t2at(to0)) ;}
    |
    to0="["
    to1=<IDENTIFIER>
    to2="]"
    {return new OptTerm().setParms (t2at(to0), t2at(to1), t2at(to2)) ;}
}

IExpr IExpr () : {
    IExpr ie0=null ;
    OExpr oe0=null ;
    Token to0=null ;
} {
    // Merged productions from rule IExpr
    // (*) OExpr
    // (*) OExpr "implies" IExpr :: BImplies
    // 
    oe0=OExpr()
    [
        LOOKAHEAD(2)
        to0="implies"
        ie0=IExpr()
        {return new BImplies().setParms (oe0, t2at(to0), ie0) ;}
    ]
    {return (IExpr) oe0 ;}
}

NExpr NExpr () : {
    BExpr be0=null ;
    NExpr ne0=null ;
    Token to0=null ;
} {
    be0=BExpr()
    {return (NExpr) be0 ;}
    |
    to0="not"
    ne0=NExpr()
    {return new BNot().setParms (t2at(to0), ne0) ;}
}

OExpr OExpr () : {
    AExpr ae0=null ;
    OExpr oe0=null ;
    Token to0=null ;
} {
    // Merged productions from rule OExpr
    // (*) AExpr
    // (*) AExpr "or" OExpr :: BOr
    // 
    ae0=AExpr()
    [
        LOOKAHEAD(2)
        to0="or"
        oe0=OExpr()
        {return new BOr().setParms (ae0, t2at(to0), oe0) ;}
    ]
    {return (OExpr) ae0 ;}
}

Opt Opt () : {
    Token to2=null, to1=null, to0=null ;
} {
    LOOKAHEAD(2) 
    to0=<IDENTIFIER>
    to1="="
    to2=<STRING_LITERAL>
    {return new Strlit().setParms (t2at(to0), t2at(to1), t2at(to2)) ;}
    |
    to0=<IDENTIFIER>
    {return new Optid().setParms (t2at(to0)) ;}
}

Opts Opts () : {
    Opts list = new Opts () ;
    Opt op0=null ;
} {
    (
        op0=Opt()
        {list.add (new OptsElem().setParms (op0)) ;}
    )+
    {return list ;}
}

Pat Pat () : {
    TermList te0=null ;
    Token to1=null, to0=null ;
} {
    LOOKAHEAD(2) 
    te0=TermList()
    to0="::"
    to1=<IDENTIFIER>
    {return new GPattern().setParms (te0, t2at(to0), t2at(to1)) ;}
    |
    to0=<IDENTIFIER>
    {return new SimplePattern().setParms (t2at(to0)) ;}
}

Pats Pats () : {
    Pats list = new Pats () ;
    Pat pa0=null ;
    Token to0=null ;
} {
    pa0=Pat()
    {list.add (new PatsElem().setParms (pa0)) ;}
    (
        to0="|"
        pa0=Pat()
        {list.add (new PatsElem().setParms (t2at(to0), pa0)) ;}
    )*
    {return list ;}
}

Prods Prods () : {
    Prods list = new Prods () ;
    GProd gp0=null ;
} {
    (
        gp0=GProd()
        {list.add (new ProdsElem().setParms (gp0)) ;}
    )+
    {return list ;}
}

TermList TermList () : {
    TermList list = new TermList () ;
    GTerm gt0=null ;
} {
    (
        gt0=GTerm()
        {list.add (new TermListElem().setParms (gt0)) ;}
    )+
    {return list ;}
}

Vars Vars () : {
    AvarList av0=null ;
    Token to0=null ;
} {
    to0="##"
    av0=AvarList()
    {return new VarStmt().setParms (t2at(to0), av0) ;}
}

//-----------------------------------//
// Other standard tokens::
//-----------------------------------//

TOKEN : {
    <IDENTIFIER: <LETTER> (<LETTER> | <DIGIT>)*>
    | <OTHER: ~[]>
}
